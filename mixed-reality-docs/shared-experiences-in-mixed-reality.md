---
title: Mixed reality での共有エクスペリエンス
description: Holographic アプリでは、1つの HoloLens から別の HoloLens に空間アンカーを共有することができます。これにより、ユーザーは、複数のデバイスにわたって、現実世界の同じ場所でホログラムをレンダリングできるようになります。
author: thetuvix
ms.author: grbury
ms.date: 02/10/2019
ms.topic: article
keywords: 共有エクスペリエンス、mixed reality、ホログラム、空間アンカー、マルチユーザー、複数
ms.openlocfilehash: c846bcd8c9c52f1f169d306df3afd4f982656078
ms.sourcegitcommit: 2cf3f19146d6a7ba71bbc4697a59064b4822b539
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/12/2019
ms.locfileid: "73926929"
---
# <a name="shared-experiences-in-mixed-reality"></a>Mixed reality での共有エクスペリエンス

ホログラムは、1人のユーザーに対してプライベートな状態を維持する必要はありません。 Holographic アプリでは、1つの HoloLens、iOS、または Android デバイスから別のデバイスに[空間アンカー](spatial-anchors.md)を共有することができます。これにより、ユーザーは、複数のデバイスにわたって、実際の世界の同じ場所でホログラムをレンダリングできるようになります。

## <a name="six-questions-to-define-shared-scenarios"></a>共有シナリオを定義する6つの質問

共有エクスペリエンスの設計を開始する前に、ターゲットシナリオを定義することが重要です。 これらのシナリオは、設計対象を明確にし、エクスペリエンスに必要な機能の比較とコントラストを行うための共通の語彙を確立するのに役立ちます。 主要な問題とソリューションのさまざまな手段を理解することは、この新しいメディアに固有の機会を明らかにするための鍵です。

HoloLens パートナー機関の内部プロトタイプと探索を通じて、共有シナリオの定義に役立つ6つの質問を作成しました。 これらの質問は、シナリオの重要な属性を抽出するために、包括的なものではなく、フレームワークを形成します。

### <a name="1-how-are-they-sharing"></a>1. 共有について教えてください。

プレゼンテーションは1つの仮想ユーザーによって主導される場合がありますが、複数のユーザーが共同作業を行うことができます。または、教師が仮想資料を扱う仮想学生にガイダンスを提供する場合もあります。エクスペリエンスの複雑さは、ユーザーが持つ機関のレベルに基づいて増加します。は、シナリオでを持つことができます。

![Holograph on table を使用した Man と女性](images/man-and-women-with-holograph-on-table-500px.png)

共有するにはさまざまな方法がありますが、そのほとんどは次の3つのカテゴリに分類されています。

* **プレゼンテーション**: 同じコンテンツが複数のユーザーに表示されている場合。 たとえば、すべてのユーザーに同じ holographic マテリアルを使用して、複数の学生に講義を行うことができます。 ただし、教授には、他のユーザーには表示されない可能性がある独自のヒントやメモを含めることができます。
* **共同**作業: 複数の担当者が連携して、一般的な目標を達成します。 たとえば、次の例では、プロジェクトを使用して、ハートの手術を実行する方法を学習しました。 学生は、共有スキルラボエクスペリエンスをペアにして作成します。これにより、医療学生はハートのモデルで共同作業を行い、学ぶことができます。
* **ガイダンス**: 1 人のユーザーが、より1対1のスタイルの相互作用で問題を解決するのを支援しています。 たとえば、ユーザーが共有エクスペリエンスでハート・・スキルラボを実行している場合に、学生にガイダンスを提供します。

### <a name="2-what-is-the-group-size"></a>2. グループサイズとは何ですか。

**1 対 1**の共有エクスペリエンスによって、強力なベースラインが提供され、概念実証をこのレベルで作成できることが理想的です。 ただし、(6 つを超える) 大規模なグループと共有すると、技術 (データとネットワーク) とソーシャルの両方が困難になる可能性があることに注意してください ([複数のアバター](https://vimeo.com/160704056)がある部屋に与える影響)。 **小規模**から**大規模なグループ**に移行すると、複雑さが指数関数的に増加します。

グループのニーズは、次の3つのサイズのカテゴリに分類されることがわかりました。
* 1:1
* 小 < 7
* 大きい > = 7

グループサイズは、次のように影響するため、重要な質問になります。

* Holographic space での人間の表現
* オブジェクトのスケール
* 環境のスケール

### <a name="3-where-is-everyone"></a>3. だれが誰であるか。

混合現実の強みは、共有エクスペリエンスを同じ場所で実行できるようになったときに再生されます。 これを**併置**と呼びます。 逆に、グループが配布され、少なくとも1つの参加要素が同じ物理空間に存在しない場合 (通常、VR の場合と同じように)、**リモートエクスペリエンス**を呼び出します。 多くの場合、グループに併置とリモートの**両方**の参加要素があります (会議室の2つのグループなど)。

![Holograph on table を持つ3人の人](images/three-people-with-holograph-on-table-500px.png)

次のカテゴリを使用すると、ユーザーの所在地を伝えることができます。

* **併置**: すべてのユーザーが同じ物理領域に配置されます。
* **リモート**: すべてのユーザーが別々の物理スペースに配置されます。
* **両方**: ユーザーは、併置された場所とリモートのスペースを組み合わせたものになります。

この質問は、次のような影響を及ぼすため、非常に重要です。

* 相手の通信方法
    * 例: アバターを使用する必要があるかどうか。
* 表示されるオブジェクト。 すべてのオブジェクトが共有されていますか?
* 環境に合わせて調整する必要があるかどうか。

### <a name="4-when-are-they-sharing"></a>4. 共有するのはいつですか?

一般に、共有エクスペリエンスが気になると、**同期**エクスペリエンスが考えられます。これは、すべてをまとめたものです。 しかし、他のユーザーによって追加された単一の仮想要素が含まれている場合は、**非同期**のシナリオがあります。 仮想環境にノートや音声メモが残されていることを想像してください。 どのようにして、設計に100の仮想メモをどのように処理しますか。 さまざまなレベルのプライバシーを持つ多数のユーザーがいる場合はどうでしょうか。

次のいずれかの時間について、エクスペリエンスを検討してください。

* **同期的**: holographic experience を同時に共有します。 たとえば、2人の学生が同時にスキルラボを実行するとします。
* **非同期**: さまざまなタイミングで holographic エクスペリエンスを共有します。 たとえば、2人の学生がスキルラボを実行していて、異なるタイミングで別のセクションを操作しているとします。
* **両方**: ユーザーは同期的に共有される場合がありますが、非同期的に共有される場合もあります。 たとえば、生徒が後で学生に対して実行した割り当てを、次の日に生徒にメモしたままにするとします。

この質問は、次のような影響を与えるため重要です。

* オブジェクトと環境の永続性。 たとえば、状態を格納して取得できるようにします。
* ユーザーの視点。 たとえば、メモを残したときにユーザーが見ていたことを覚えているとします。

### <a name="5-how-similar-are-their-physical-environments"></a>5. 物理的な環境を類似しているかどうか。

2つの同一の実環境が併置されていない場合は、それらの環境が同じものになるように設計されていない限り、スリムになります。 **類似**した環境を使用している可能性が高くなります。 たとえば、会議室は似ています。通常は、中央に配置されたテーブルが椅子で囲まれています。 一方、生きた部屋は、通常は**異なる**ため、無制限のレイアウトの配列に任意の数の家具を含めることができます。

![テーブル上の Holograph](images/holograph-on-table-500px.png)

共有エクスペリエンスは、次の2つのカテゴリのいずれかに分類されることを考慮してください。

* **同様**に、類似した家具、アンビエント光とサウンド、物理的な部屋のサイズを持つ環境です。 たとえば、教授が講義の hall であり、学生が講演者 B にいるとします。講義を行うのは、B よりも椅子が少なくても、両方ともホログラムを配置する物理的な机がある可能性があります。
* **異種**: 家具の設定、部屋のサイズ、ライトとサウンドに関する考慮事項がかなり異なる環境。 たとえば、教師は集中ルームにあり、学生は大規模な講義のホールにあり、学生や教師によって設定されています。

次のように、[環境について考慮](environment-considerations-for-hololens.md)することが重要です。

* これらのオブジェクトをどのように経験するかを説明します。 たとえば、ユーザーがテーブルを使用していて、ユーザーにテーブルがない場合は、次のようになります。 または平らな床面では、ユーザーには乱雑な領域があります。
* オブジェクトのスケール。 たとえば、テーブルに6フィートのヒューマンモデルを配置することは困難な場合がありますが、ハートのモデルはうまく機能します。

### <a name="6-what-devices-are-they-using"></a>6. 使用しているデバイス

現在、2つの[**イマーシブデバイス**](immersive-headset-hardware-details.md)間で共有されたエクスペリエンスが見られる可能性があります (これらのデバイスは、ボタンと相対機能の観点では若干異なる場合がありますが、これら**のデバイスは**、対象となるソリューションによって若干異なる場合があります)。これらのデバイスの場合。 ただし、2d**デバイス**(モバイル/デスクトップの参加要素またはオブザーバー) が、特に**2d および3d デバイスが混在**している場合に必要な考慮事項になるかどうかを検討してください。 参加者が使用するデバイスの種類を理解することは、さまざまな忠実性とデータの制約と機会があるだけでなく、各プラットフォームに固有の期待があるため、重要です。

## <a name="exploring-the-potential-of-shared-experiences"></a>共有エクスペリエンスの可能性の調査

上記の質問に対する回答を組み合わせると、共有シナリオをより深く理解し、エクスペリエンスを拡張する際の課題を crystallizing ことができます。 Microsoft のチームにとって、これにより、現在使用しているエクスペリエンスを向上させるためのロードマップを確立し、これらの複雑な問題の詳細を理解し、mixed reality で共有エクスペリエンスを活用する方法を理解できました。

たとえば、HoloLens 起動からの Skype のシナリオの1つを考えてみます。ユーザーは、離れた場所にあるエキスパートからのヘルプを使用して、破損した[ライトスイッチを修正する方法](https://www.youtube.com/watch?v=iBfzs3G8BEA)を実行しました。

![Skype for HoloLens を使用したライトスイッチの修正](images/fix-a-broken-switch-with-hololens-640px.jpg)

*専門家は、 **2d**、デスクトップコンピューターから、 **3d の混合現実**デバイスのユーザーに**1:1**のガイダンスを提供します。この**ガイダンス**は**同期** **であり、** 物理的な環境は異なります。*

このようなエクスペリエンスは、現在のエクスペリエンスからのステップ変更であり、ビデオと音声のパラダイムを新しいメディアに適用しています。 しかし、将来的に見られるように、混合現実の強度を反映するシナリオとビルドエクスペリエンスの機会をより適切に定義する必要があります。

NASA のジェット推進研究所によって開発された、 [Onsight コラボレーションツール](https://www.youtube.com/watch?v=XtUyUJAVQ6w)を考えてみましょう。 Rover ミッションのデータを操作する科学者は、Martian ランドスケープのデータ内で同僚と共同作業を行うことができます。

![リモートで分離された同僚と Mars Rover の計画作業を相互に連携させる](images/onsight-nasa-jpl.gif)

*科学者は、3d デバイスと**2d**デバイスを使用して、**少数**の**リモート**仕事仲間グループを持つ、 **3d の混合現実**デバイスを使用した環境を探索します。**コラボレーション**は**同期**されていますが (非同期に再検討できます)、物理的な環境は (事実上)**似**ています。*

OnSight のような経験があれば、コラボレーションが新たにチャンスになります。 仮想環境内の要素を、同僚の隣に向かって物理的にポイントし、その結果を説明するためにそれらの視点を共有します。 Immersion のレンズとプレゼンスを使用して、mixed reality での共有エクスペリエンスを再考します。

直感的なコラボレーションとは、会話の基盤、連携して、この直感を mixed reality の複雑さに適用する方法を理解することが重要です。 混合環境での共有エクスペリエンスを再作成するだけでなく、それを大量に使用できる場合は、将来の作業のパラダイムシフトになります。 混合環境での共有エクスペリエンスの設計は、新たに魅力的なスペースです。最初にしかありません。

## <a name="get-started-building-shared-experiences"></a>共有エクスペリエンスの構築を開始する

アプリケーションとシナリオに応じて、必要なエクスペリエンスを実現するためのさまざまな要件があります。 次のようなものがあります。

* **一致**: セッションの作成、セッションのアドバタイズ、特定のユーザーの検出と招待を、ローカルとリモートの両方でセッションに参加させることができます。
* **アンカー共有**: 共通のローカル空間内の複数のデバイス間で座標を調整できるため、ホログラムはすべてのメンバーに対して同じ場所に表示されます。
* **ネットワーク**: すべての参加者に対して、人とホログラムの位置、相互作用、および移動をリアルタイムで同期させる機能。
* **状態の格納**: ホログラムの特性と場所を、セッション間の結合のためのスペースに格納する機能、後で再呼び出し、ネットワークの問題に対する堅牢性。

共有エクスペリエンスの鍵となるのは、複数のユーザーが自分のデバイスで世界中の同じホログラムを見ることです。多くの場合、アンカーを共有してデバイス間で座標を調整します。

アンカーを共有するには、 [Azure 空間アンカー](https://docs.microsoft.com/azure/spatial-anchors)を使用します。

* まず、ユーザーがホログラムを配置します。
* アプリは[空間アンカー](spatial-anchors.md)を作成し、世界中でそのホログラムを正確にピン留めします。
* アンカーは、 [Azure 空間アンカー](https://docs.microsoft.com/azure/spatial-anchors/)を介して HoloLens、iOS、および Android デバイスに対して共有できます。

共有空間アンカーを使用すると、各デバイスのアプリには、コンテンツを配置できる[共通の座標](coordinate-systems.md)系が用意されます。 これで、アプリは、同じ場所にホログラムを配置し、向きを指定できるようになりました。

HoloLens デバイスでは、あるデバイスから別のデバイスにアンカーをオフラインで共有することもできます。  次のリンクを使用して、アプリケーションに最適なものを決定します。

## <a name="evaluating-tech-options"></a>技術オプションの評価

マルチユーザー混合の現実のエクスペリエンスを構築するのに役立つさまざまなサービスおよびテクノロジオプションが用意されています。  パスを選択するのは難しい場合があるため、シナリオに重点を置いた観点から、いくつかのオプションについて詳しく説明します。

## <a name="shared-static-holograms-no-interactions"></a>共有スタティックホログラム (相互作用なし)

アプリで[Azure 空間アンカー](https://docs.microsoft.com/azure/spatial-anchors/)を活用します。  デバイス間で空間アンカーを有効にして共有すると、ユーザーが同時にホログラムを表示するアプリケーションを作成できます。  ユーザーがホログラムと対話し、ホログラムの移動または状態の更新を確認できるようにするには、デバイス間の追加の同期が必要です。

## <a name="share-1st-person-perspective"></a>ファーストユーザーの視点を共有する

PC や TV など、サポートされている Miracast レシーバーを使用している場合、ローカルユーザーには組み込みの Miracast サポートを利用します。追加のアプリコードは必要ありません。

リモートユーザーに対して、または共有したい非 Miracast デバイスがある場合に、アプリで[MixedReality-WebRTC](https://github.com/microsoft/mixedreality-webrtc)を活用します。  WebRTC 接続を有効にすると、ユーザー間で1:1 のオーディオ/ビデオストリームが有効になり、デバイス間のメッセージング用のデータチャネルも使用できるようになります。  Mixed reality の実装では、HoloLens ユーザーのビューの混合 reality キャプチャビデオストリームを他のユーザーに提供することで、HoloLens を最適化します。  複数のリモートクライアントに対してビデオストリーミングをスケールアップする場合は、通常、 [Signalwire](https://signalwire.com/)など、 [MCU サービスプロバイダー](https://webrtcglossary.com/mcu/) (Multipoint 会議単位) が使用されます。  Azure へのワンクリック SignalWire デプロイは、 [Freeswitch](https://github.com/andywolk/azure-freeswitch-gpu-windows)経由で利用できます。

> [!NOTE]
> ただし、SignalWire は有料サービスであり、Microsoft との所有/関連はありません。

## <a name="presenter-spectator-applications-and-demos"></a>プレゼンター Spectator アプリケーションとデモ

[MixedReality-SpectatorView](https://github.com/microsoft/MixedReality-SpectatorView)を利用して、 [spectator ビュー機能](spectator-view.md)をアプリに取り込むことができます。  他のデバイス (HL、Android、iOS、およびビデオカメラ) を有効にすると、同じ場所にあるさまざまな観点から HoloLens がどのように見えるかを確認し、ホログラムと対話するホスト HoloLens ユーザーの相互作用に関する更新を受け取ることができます。  同じアプリの spectator コンパニオンを使用して、独自の空間パースペクティブから、アプリケーション内のホログラムによってホストが行う処理のビデオを視聴、撮影、記録します。

**注:** 画像は、iOS/Android デバイスのスクリーンショットを使用して取得されます。

## <a name="multi-user-collaborative-experience"></a>マルチユーザーコラボレーションエクスペリエンス

ここでは、[マルチユーザー学習チュートリアル](mrlearning-sharing(photon)-ch1.md)を開始します。このチュートリアルでは、ローカルユーザーと[Photon SDK](https://www.photonengine.com/PUN)の[Azure 空間アンカー](https://docs.microsoft.com/azure/spatial-anchors/)を利用して、シーンのコンテンツ/状態を同期します。 ローカルに共同作業するアプリケーションを作成します。各ユーザーは、シーン内のホログラムに独自の視点を持ち、各ユーザーがホログラムと完全に対話できます。  すべてのデバイスで更新プログラムが提供され、相互作用の競合管理は Photon によって処理されます。

> [!NOTE]
> [Photon](https://www.photonengine.com/)はマイクロソフト以外の製品であるため、Photon との課金関係が必要になることがあります。そのため、使用率が高くなるように拡張する必要があります。

## <a name="future-work"></a>今後の作業

コンポーネントの機能とインターフェイスは、さまざまなシナリオや基盤となるテクノロジに共通の一貫性と堅牢なサポートを提供するのに役立ちます。  それまでは、アプリケーションで達成しようとしているシナリオに合わせた最適なパスを選択します。

別のテクノロジ/サービスを使用するシナリオや希望が異なる場合は、 このページの下部にある対応するリポジトリで GitHub の問題としてフィードバックを提供するか、 [HoloDevelopers の余裕期間](https://holodevelopers.slack.com/)にご連絡ください。

## <a name="see-also"></a>関連項目

* [Azure Spatial Anchors](https://docs.microsoft.com/azure/spatial-anchors)
* [DirectX での共有された空間アンカー](shared-spatial-anchors-in-directx.md)
* [Unity での共有エクスペリエンス](shared-experiences-in-unity.md)
* [Spectator View](spectator-view.md)
