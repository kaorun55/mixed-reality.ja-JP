---
title: Mixed reality での共有エクスペリエンス
description: Holographic アプリでは、1つの HoloLens から別の HoloLens に空間アンカーを共有することができます。これにより、ユーザーは、複数のデバイスにわたって、現実世界の同じ場所でホログラムをレンダリングできるようになります。
author: thetuvix
ms.author: grbury
ms.date: 02/10/2019
ms.topic: article
keywords: 共有エクスペリエンス、mixed reality、ホログラム、空間アンカー、マルチユーザー、複数
ms.openlocfilehash: 4e71bdefa32d2f6cf3b85b074c3d9fcbdb6aa909
ms.sourcegitcommit: 6bc6757b9b273a63f260f1716c944603dfa51151
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/01/2019
ms.locfileid: "73437470"
---
# <a name="shared-experiences-in-mixed-reality"></a><span data-ttu-id="efe07-104">Mixed reality での共有エクスペリエンス</span><span class="sxs-lookup"><span data-stu-id="efe07-104">Shared experiences in mixed reality</span></span>

<span data-ttu-id="efe07-105">ホログラムは、1人のユーザーに対してプライベートな状態を維持する必要はありません。</span><span class="sxs-lookup"><span data-stu-id="efe07-105">Holograms don't need to stay private to just one user.</span></span> <span data-ttu-id="efe07-106">Holographic アプリでは、1つの HoloLens、iOS、または Android デバイスから別のデバイスに[空間アンカー](spatial-anchors.md)を共有することができます。これにより、ユーザーは、複数のデバイスにわたって、実際の世界の同じ場所でホログラムをレンダリングできるようになります。</span><span class="sxs-lookup"><span data-stu-id="efe07-106">Holographic apps may share [spatial anchors](spatial-anchors.md) from one HoloLens, iOS or Android device to another, enabling users to render a hologram at the same place in the real world across multiple devices.</span></span>

## <a name="six-questions-to-define-shared-scenarios"></a><span data-ttu-id="efe07-107">共有シナリオを定義する6つの質問</span><span class="sxs-lookup"><span data-stu-id="efe07-107">Six questions to define shared scenarios</span></span>

<span data-ttu-id="efe07-108">共有エクスペリエンスの設計を開始する前に、ターゲットシナリオを定義することが重要です。</span><span class="sxs-lookup"><span data-stu-id="efe07-108">Before you begin designing for shared experiences, it’s important to define the target scenarios.</span></span> <span data-ttu-id="efe07-109">これらのシナリオは、設計対象を明確にし、エクスペリエンスに必要な機能の比較とコントラストを行うための共通の語彙を確立するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="efe07-109">These scenarios help clarify what you’re designing and establish a common vocabulary to help compare and contrast features required in your experience.</span></span> <span data-ttu-id="efe07-110">主要な問題とソリューションのさまざまな手段を理解することは、この新しいメディアに固有の機会を明らかにするための鍵です。</span><span class="sxs-lookup"><span data-stu-id="efe07-110">Understanding the core problem, and the different avenues for solutions, is key to uncovering opportunities inherent in this new medium.</span></span>

<span data-ttu-id="efe07-111">HoloLens パートナー機関の内部プロトタイプと探索を通じて、共有シナリオの定義に役立つ6つの質問を作成しました。</span><span class="sxs-lookup"><span data-stu-id="efe07-111">Through internal prototypes and explorations from our HoloLens partner agencies, we created six questions to help you define shared scenarios.</span></span> <span data-ttu-id="efe07-112">これらの質問は、シナリオの重要な属性を抽出するために、包括的なものではなく、フレームワークを形成します。</span><span class="sxs-lookup"><span data-stu-id="efe07-112">These questions form a framework, not intended to be exhaustive, to help distill the important attributes of your scenarios.</span></span>

### <a name="1-how-are-they-sharing"></a><span data-ttu-id="efe07-113">1. 共有について教えてください。</span><span class="sxs-lookup"><span data-stu-id="efe07-113">1. How are they sharing?</span></span>

<span data-ttu-id="efe07-114">プレゼンテーションは1つの仮想ユーザーによって主導される場合がありますが、複数のユーザーが共同作業を行うことができます。または、教師が仮想資料を扱う仮想学生にガイダンスを提供する場合もあります。エクスペリエンスの複雑さは、ユーザーが持つ機関のレベルに基づいて増加します。は、シナリオでを持つことができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-114">A presentation might be led by a single virtual user, while multiple users can collaborate, or a teacher might provide guidance to virtual students working with virtual materials — the complexity of the experiences increases based on the level of agency a user has or can have in a scenario.</span></span>

![Holograph on table を使用した Man と女性](images/man-and-women-with-holograph-on-table-500px.png)

<span data-ttu-id="efe07-116">共有するにはさまざまな方法がありますが、そのほとんどは次の3つのカテゴリに分類されています。</span><span class="sxs-lookup"><span data-stu-id="efe07-116">There are many ways to share, but we’ve found that most of them fall into three categories:</span></span>

* <span data-ttu-id="efe07-117">**プレゼンテーション**: 同じコンテンツが複数のユーザーに表示されている場合。</span><span class="sxs-lookup"><span data-stu-id="efe07-117">**Presentation**: When the same content is being shown to several users.</span></span> <span data-ttu-id="efe07-118">たとえば、すべてのユーザーに同じ holographic マテリアルを使用して、複数の学生に講義を行うことができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-118">For example: A professor is giving out a lecture to several students using the same holographic material being presented to everyone.</span></span> <span data-ttu-id="efe07-119">ただし、教授には、他のユーザーには表示されない可能性がある独自のヒントやメモを含めることができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-119">The professor, however, could have his/her own hints and notes that may not be visible to others.</span></span>
* <span data-ttu-id="efe07-120">**共同**作業: 複数の担当者が連携して、一般的な目標を達成します。</span><span class="sxs-lookup"><span data-stu-id="efe07-120">**Collaboration**: When people are working together to achieve some common goals.</span></span> <span data-ttu-id="efe07-121">たとえば、次の例では、プロジェクトを使用して、ハートの手術を実行する方法を学習しました。</span><span class="sxs-lookup"><span data-stu-id="efe07-121">For example: The professor gave out a project to learn about performing a heart surgery.</span></span> <span data-ttu-id="efe07-122">学生は、共有スキルラボエクスペリエンスをペアにして作成します。これにより、医療学生はハートのモデルで共同作業を行い、学ぶことができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-122">Students pair up and create a shared skills lab experience which allows medical students to collaborate on the heart model and learn.</span></span>
* <span data-ttu-id="efe07-123">**ガイダンス**: 1 人のユーザーが、より1対1のスタイルの相互作用で問題を解決するのを支援しています。</span><span class="sxs-lookup"><span data-stu-id="efe07-123">**Guidance**: When one person is helping someone to solve a problem in a more one-to-one style interaction.</span></span> <span data-ttu-id="efe07-124">たとえば、ユーザーが共有エクスペリエンスでハート・・スキルラボを実行している場合に、学生にガイダンスを提供します。</span><span class="sxs-lookup"><span data-stu-id="efe07-124">For example: The professor giving guidance to a student when he/she is performing the heart surgery skills lab in the shared experience.</span></span>

### <a name="2-what-is-the-group-size"></a><span data-ttu-id="efe07-125">2. グループサイズとは何ですか。</span><span class="sxs-lookup"><span data-stu-id="efe07-125">2. What is the group size?</span></span>

<span data-ttu-id="efe07-126">**1 対 1**の共有エクスペリエンスによって、強力なベースラインが提供され、概念実証をこのレベルで作成できることが理想的です。</span><span class="sxs-lookup"><span data-stu-id="efe07-126">**One-to-one** sharing experiences can provide a strong baseline and ideally your proofs of concept can be created at this level.</span></span> <span data-ttu-id="efe07-127">ただし、(6 つを超える) 大規模なグループと共有すると、技術 (データとネットワーク) とソーシャルの両方が困難になる可能性があることに注意してください ([複数のアバター](https://vimeo.com/160704056)がある部屋に与える影響)。</span><span class="sxs-lookup"><span data-stu-id="efe07-127">But be aware that sharing with large groups (beyond 6 people) can lead to difficulties both technical (data and networking) and social (the impact of being in a room with [several avatars](https://vimeo.com/160704056)).</span></span> <span data-ttu-id="efe07-128">**小規模**から**大規模なグループ**に移行すると、複雑さが指数関数的に増加します。</span><span class="sxs-lookup"><span data-stu-id="efe07-128">Complexity increases exponentially as you go from **small** to **large groups**.</span></span>

<span data-ttu-id="efe07-129">グループのニーズは、次の3つのサイズのカテゴリに分類されることがわかりました。</span><span class="sxs-lookup"><span data-stu-id="efe07-129">We have found that the needs of groups can fall into three size categories:</span></span>
* <span data-ttu-id="efe07-130">1:1</span><span class="sxs-lookup"><span data-stu-id="efe07-130">1:1</span></span>
* <span data-ttu-id="efe07-131">小 < 7</span><span class="sxs-lookup"><span data-stu-id="efe07-131">Small < 7</span></span>
* <span data-ttu-id="efe07-132">大きい > = 7</span><span class="sxs-lookup"><span data-stu-id="efe07-132">Large >= 7</span></span>

<span data-ttu-id="efe07-133">グループサイズは、次のように影響するため、重要な質問になります。</span><span class="sxs-lookup"><span data-stu-id="efe07-133">Group size makes for an important question because it influences:</span></span>

* <span data-ttu-id="efe07-134">Holographic space での人間の表現</span><span class="sxs-lookup"><span data-stu-id="efe07-134">Representations of people in holographic space</span></span>
* <span data-ttu-id="efe07-135">オブジェクトのスケール</span><span class="sxs-lookup"><span data-stu-id="efe07-135">Scale of objects</span></span>
* <span data-ttu-id="efe07-136">環境のスケール</span><span class="sxs-lookup"><span data-stu-id="efe07-136">Scale of environment</span></span>

### <a name="3-where-is-everyone"></a><span data-ttu-id="efe07-137">3. だれが誰であるか。</span><span class="sxs-lookup"><span data-stu-id="efe07-137">3. Where is everyone?</span></span>

<span data-ttu-id="efe07-138">混合現実の強みは、共有エクスペリエンスを同じ場所で実行できるようになったときに再生されます。</span><span class="sxs-lookup"><span data-stu-id="efe07-138">The strength of mixed reality comes into play when a shared experience can take place in the same location.</span></span> <span data-ttu-id="efe07-139">これを**併置**と呼びます。</span><span class="sxs-lookup"><span data-stu-id="efe07-139">We call that **co-located**.</span></span> <span data-ttu-id="efe07-140">逆に、グループが配布され、少なくとも1つの参加要素が同じ物理空間に存在しない場合 (通常、VR の場合と同じように)、**リモートエクスペリエンス**を呼び出します。</span><span class="sxs-lookup"><span data-stu-id="efe07-140">Conversely, when the group is distributed and at least one participant is not in the same physical space (as is often the case with VR) we call that a **remote experience**.</span></span> <span data-ttu-id="efe07-141">多くの場合、グループに併置とリモートの**両方**の参加要素があります (会議室の2つのグループなど)。</span><span class="sxs-lookup"><span data-stu-id="efe07-141">Often, it’s the case that your group has **both** co-located and remote participants (e.g. two groups in conference rooms).</span></span>

![Holograph on table を持つ3人の人](images/three-people-with-holograph-on-table-500px.png)

<span data-ttu-id="efe07-143">次のカテゴリを使用すると、ユーザーの所在地を伝えることができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-143">Following categories help convey where users are located:</span></span>

* <span data-ttu-id="efe07-144">**併置**: すべてのユーザーが同じ物理領域に配置されます。</span><span class="sxs-lookup"><span data-stu-id="efe07-144">**Co-located**: All your users will be in the same physical space.</span></span>
* <span data-ttu-id="efe07-145">**リモート**: すべてのユーザーが別々の物理スペースに配置されます。</span><span class="sxs-lookup"><span data-stu-id="efe07-145">**Remote**: All your users will be in separate physical spaces.</span></span>
* <span data-ttu-id="efe07-146">**両方**: ユーザーは、併置された場所とリモートのスペースを組み合わせたものになります。</span><span class="sxs-lookup"><span data-stu-id="efe07-146">**Both**: Your users will be a mix of co-located and remote spaces.</span></span>

<span data-ttu-id="efe07-147">この質問は、次のような影響を及ぼすため、非常に重要です。</span><span class="sxs-lookup"><span data-stu-id="efe07-147">This question is crucial because it influences:</span></span>

* <span data-ttu-id="efe07-148">相手の通信方法</span><span class="sxs-lookup"><span data-stu-id="efe07-148">How people communicate?</span></span>
    * <span data-ttu-id="efe07-149">例: アバターを使用する必要があるかどうか。</span><span class="sxs-lookup"><span data-stu-id="efe07-149">For example: Whether they should have avatars?</span></span>
* <span data-ttu-id="efe07-150">表示されるオブジェクト。</span><span class="sxs-lookup"><span data-stu-id="efe07-150">What objects they see.</span></span> <span data-ttu-id="efe07-151">すべてのオブジェクトが共有されていますか?</span><span class="sxs-lookup"><span data-stu-id="efe07-151">Are all objects shared?</span></span>
* <span data-ttu-id="efe07-152">環境に合わせて調整する必要があるかどうか。</span><span class="sxs-lookup"><span data-stu-id="efe07-152">Whether we need to adapt to their environment?</span></span>

### <a name="4-when-are-they-sharing"></a><span data-ttu-id="efe07-153">4. 共有するのはいつですか?</span><span class="sxs-lookup"><span data-stu-id="efe07-153">4. When are they sharing?</span></span>

<span data-ttu-id="efe07-154">一般に、共有エクスペリエンスが気になると、**同期**エクスペリエンスが考えられます。これは、すべてをまとめたものです。</span><span class="sxs-lookup"><span data-stu-id="efe07-154">We typically think of **synchronous** experiences when shared experiences come to mind: We’re all doing it together.</span></span> <span data-ttu-id="efe07-155">しかし、他のユーザーによって追加された単一の仮想要素が含まれている場合は、**非同期**のシナリオがあります。</span><span class="sxs-lookup"><span data-stu-id="efe07-155">But if we include a single, virtual element that was added by someone else, we have an **asynchronous** scenario.</span></span> <span data-ttu-id="efe07-156">仮想環境にノートや音声メモが残されていることを想像してください。</span><span class="sxs-lookup"><span data-stu-id="efe07-156">Imagine a note, or voice memo, left in a virtual environment.</span></span> <span data-ttu-id="efe07-157">どのようにして、設計に100の仮想メモをどのように処理しますか。</span><span class="sxs-lookup"><span data-stu-id="efe07-157">How do you handle 100 virtual memos left on your design?</span></span> <span data-ttu-id="efe07-158">さまざまなレベルのプライバシーを持つ多数のユーザーがいる場合はどうでしょうか。</span><span class="sxs-lookup"><span data-stu-id="efe07-158">What if they’re from dozens of people with different levels of privacy?</span></span>

<span data-ttu-id="efe07-159">次のいずれかの時間について、エクスペリエンスを検討してください。</span><span class="sxs-lookup"><span data-stu-id="efe07-159">Consider your experiences as one of these categories of time:</span></span>

* <span data-ttu-id="efe07-160">**同期的**: holographic experience を同時に共有します。</span><span class="sxs-lookup"><span data-stu-id="efe07-160">**Synchronously**: Sharing the holographic experience at the same time.</span></span> <span data-ttu-id="efe07-161">たとえば、2人の学生が同時にスキルラボを実行するとします。</span><span class="sxs-lookup"><span data-stu-id="efe07-161">For example: Two students performing the skills lab at the same time.</span></span>
* <span data-ttu-id="efe07-162">**非同期**: さまざまなタイミングで holographic エクスペリエンスを共有します。</span><span class="sxs-lookup"><span data-stu-id="efe07-162">**Asynchronously**: Sharing the holographic experience at different times.</span></span> <span data-ttu-id="efe07-163">たとえば、2人の学生がスキルラボを実行していて、異なるタイミングで別のセクションを操作しているとします。</span><span class="sxs-lookup"><span data-stu-id="efe07-163">For example: Two students performing the skills lab but working on separate sections at different times.</span></span>
* <span data-ttu-id="efe07-164">**両方**: ユーザーは同期的に共有される場合がありますが、非同期的に共有される場合もあります。</span><span class="sxs-lookup"><span data-stu-id="efe07-164">**Both**: Your users will sometimes be sharing synchronously but other times asynchronously.</span></span> <span data-ttu-id="efe07-165">たとえば、生徒が後で学生に対して実行した割り当てを、次の日に生徒にメモしたままにするとします。</span><span class="sxs-lookup"><span data-stu-id="efe07-165">For example: A professor grading the assignment performed by the students at a later time and leaving notes for students for the next day.</span></span>

<span data-ttu-id="efe07-166">この質問は、次のような影響を与えるため重要です。</span><span class="sxs-lookup"><span data-stu-id="efe07-166">This question is important because it influences:</span></span>

* <span data-ttu-id="efe07-167">オブジェクトと環境の永続性。</span><span class="sxs-lookup"><span data-stu-id="efe07-167">Object and environment persistence.</span></span> <span data-ttu-id="efe07-168">たとえば、状態を格納して取得できるようにします。</span><span class="sxs-lookup"><span data-stu-id="efe07-168">For example: Storing the states so they can be retrieved.</span></span>
* <span data-ttu-id="efe07-169">ユーザーの視点。</span><span class="sxs-lookup"><span data-stu-id="efe07-169">User perspective.</span></span> <span data-ttu-id="efe07-170">たとえば、メモを残したときにユーザーが見ていたことを覚えているとします。</span><span class="sxs-lookup"><span data-stu-id="efe07-170">For example: Perhaps remembering what the user was looking at when leaving notes.</span></span>

### <a name="5-how-similar-are-their-physical-environments"></a><span data-ttu-id="efe07-171">5. 物理的な環境を類似しているかどうか。</span><span class="sxs-lookup"><span data-stu-id="efe07-171">5. How similar are their physical environments?</span></span>

<span data-ttu-id="efe07-172">2つの同一の実環境が併置されていない場合は、それらの環境が同じものになるように設計されていない限り、スリムになります。</span><span class="sxs-lookup"><span data-stu-id="efe07-172">The likelihood of two identical real-life environments, outside of co-located experiences, is slim unless those environments have been designed to be identical.</span></span> <span data-ttu-id="efe07-173">**類似**した環境を使用している可能性が高くなります。</span><span class="sxs-lookup"><span data-stu-id="efe07-173">You’re more likely to have **similar** environments.</span></span> <span data-ttu-id="efe07-174">たとえば、会議室は似ています。通常は、中央に配置されたテーブルが椅子で囲まれています。</span><span class="sxs-lookup"><span data-stu-id="efe07-174">For example, conference rooms are similar — they typically have a centrally-located table surrounded by chairs.</span></span> <span data-ttu-id="efe07-175">一方、生きた部屋は、通常は**異なる**ため、無制限のレイアウトの配列に任意の数の家具を含めることができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-175">Living rooms, on the other hand, are usually **dissimilar** and can include any number of pieces of furniture in an infinite array of layouts.</span></span>

![テーブル上の Holograph](images/holograph-on-table-500px.png)

<span data-ttu-id="efe07-177">共有エクスペリエンスは、次の2つのカテゴリのいずれかに分類されることを考慮してください。</span><span class="sxs-lookup"><span data-stu-id="efe07-177">Consider your sharing experiences fitting into one of these two categories:</span></span>

* <span data-ttu-id="efe07-178">**同様**に、類似した家具、アンビエント光とサウンド、物理的な部屋のサイズを持つ環境です。</span><span class="sxs-lookup"><span data-stu-id="efe07-178">**Similar**: Environments that tend to have similar furniture, ambient light and sound, physical room size.</span></span> <span data-ttu-id="efe07-179">たとえば、教授が講義の hall であり、学生が講演者 B にいるとします。講義を行うのは、B よりも椅子が少なくても、両方ともホログラムを配置する物理的な机がある可能性があります。</span><span class="sxs-lookup"><span data-stu-id="efe07-179">For example: Professor is in lecture hall A and students are in lecture hall B. Lecture hall A might have fewer chairs than B but they both may have a physical desk to place holograms on.</span></span>
* <span data-ttu-id="efe07-180">**異種**: 家具の設定、部屋のサイズ、ライトとサウンドに関する考慮事項がかなり異なる環境。</span><span class="sxs-lookup"><span data-stu-id="efe07-180">**Dissimilar**: Environments that are quite different in furniture settings, room sizes, light and sound considerations.</span></span> <span data-ttu-id="efe07-181">たとえば、教師は集中ルームにあり、学生は大規模な講義のホールにあり、学生や教師によって設定されています。</span><span class="sxs-lookup"><span data-stu-id="efe07-181">For example: A professor is in a focus room whereas students are in a large lecture hall, filled with students and teachers.</span></span>

<span data-ttu-id="efe07-182">次のように、[環境について考慮](environment-considerations-for-hololens.md)することが重要です。</span><span class="sxs-lookup"><span data-stu-id="efe07-182">It's important to [think about the environment](environment-considerations-for-hololens.md), as it will influence:</span></span>

* <span data-ttu-id="efe07-183">これらのオブジェクトをどのように経験するかを説明します。</span><span class="sxs-lookup"><span data-stu-id="efe07-183">How people will experience these objects.</span></span> <span data-ttu-id="efe07-184">たとえば、ユーザーがテーブルを使用していて、ユーザーにテーブルがない場合は、次のようになります。</span><span class="sxs-lookup"><span data-stu-id="efe07-184">For example: If your experience works best on a table and the user has no table?</span></span> <span data-ttu-id="efe07-185">または平らな床面では、ユーザーには乱雑な領域があります。</span><span class="sxs-lookup"><span data-stu-id="efe07-185">Or on a flat floor surface but the user has a cluttered space.</span></span>
* <span data-ttu-id="efe07-186">オブジェクトのスケール。</span><span class="sxs-lookup"><span data-stu-id="efe07-186">Scale of the objects.</span></span> <span data-ttu-id="efe07-187">たとえば、テーブルに6フィートのヒューマンモデルを配置することは困難な場合がありますが、ハートのモデルはうまく機能します。</span><span class="sxs-lookup"><span data-stu-id="efe07-187">For example: Placing a 6 feet human model on a table could be challenging but a heart model would work great.</span></span>

### <a name="6-what-devices-are-they-using"></a><span data-ttu-id="efe07-188">6. 使用しているデバイス</span><span class="sxs-lookup"><span data-stu-id="efe07-188">6. What devices are they using?</span></span>

<span data-ttu-id="efe07-189">現在、2つの[**イマーシブデバイス**](immersive-headset-hardware-details.md)間で共有されたエクスペリエンスが見られる可能性があります (これらのデバイスは、ボタンと相対機能の観点では若干異なる場合がありますが、これら**のデバイスは**、対象となるソリューションによって若干異なる場合があります)。これらのデバイスの場合。</span><span class="sxs-lookup"><span data-stu-id="efe07-189">Today you’re often likely to see shared experiences between two [**immersive devices**](immersive-headset-hardware-details.md) (those devices might differ slightly in terms of buttons and relative capability, but not greatly) or two **holographic devices** given the solutions being targeted at these devices.</span></span> <span data-ttu-id="efe07-190">ただし、2d**デバイス**(モバイル/デスクトップの参加要素またはオブザーバー) が、特に**2d および3d デバイスが混在**している場合に必要な考慮事項になるかどうかを検討してください。</span><span class="sxs-lookup"><span data-stu-id="efe07-190">But consider if **2D devices** (a mobile/desktop participant or observer) will be a necessary consideration, especially in situations of **mixed 2D and 3D devices**.</span></span> <span data-ttu-id="efe07-191">参加者が使用するデバイスの種類を理解することは、さまざまな忠実性とデータの制約と機会があるだけでなく、各プラットフォームに固有の期待があるため、重要です。</span><span class="sxs-lookup"><span data-stu-id="efe07-191">Understanding the types of devices your participants will be using is important, not only because they come with different fidelity and data constraints and opportunities, but because users have unique expectations for each platform.</span></span>

## <a name="exploring-the-potential-of-shared-experiences"></a><span data-ttu-id="efe07-192">共有エクスペリエンスの可能性の調査</span><span class="sxs-lookup"><span data-stu-id="efe07-192">Exploring the potential of shared experiences</span></span>

<span data-ttu-id="efe07-193">上記の質問に対する回答を組み合わせると、共有シナリオをより深く理解し、エクスペリエンスを拡張する際の課題を crystallizing ことができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-193">Answers to the questions above can be combined to better understand your shared scenario, crystallizing the challenges as you expand the experience.</span></span> <span data-ttu-id="efe07-194">Microsoft のチームにとって、これにより、現在使用しているエクスペリエンスを向上させるためのロードマップを確立し、これらの複雑な問題の詳細を理解し、mixed reality で共有エクスペリエンスを活用する方法を理解できました。</span><span class="sxs-lookup"><span data-stu-id="efe07-194">For the team at Microsoft, this helped establish a road map for improving the experiences we use today, understanding the nuance of these complex problems and how to take advantage of shared experiences in mixed reality.</span></span>

<span data-ttu-id="efe07-195">たとえば、HoloLens 起動からの Skype のシナリオの1つを考えてみます。ユーザーは、離れた場所にあるエキスパートからのヘルプを使用して、破損した[ライトスイッチを修正する方法](https://www.youtube.com/watch?v=iBfzs3G8BEA)を実行しました。</span><span class="sxs-lookup"><span data-stu-id="efe07-195">For example, consider one of Skype’s scenarios from the HoloLens launch: a user worked through [how to fix a broken light switch](https://www.youtube.com/watch?v=iBfzs3G8BEA) with help from a remotely-located expert.</span></span>

![Skype for HoloLens を使用したライトスイッチの修正](images/fix-a-broken-switch-with-hololens-640px.jpg)

<span data-ttu-id="efe07-197">*専門家は、 **2d**、デスクトップコンピューターから、 **3d の混合現実**デバイスのユーザーに**1:1**のガイダンスを提供します。この**ガイダンス**は\*\*同期*\* **であり、** 物理的な環境は異なります。\*</span><span class="sxs-lookup"><span data-stu-id="efe07-197">*An expert provides **1:1** guidance from his **2D**, desktop computer to a user of a **3D, mixed-reality** device. The **guidance** is **synchronous** and the physical environments are **dissimilar**.*</span></span>

<span data-ttu-id="efe07-198">このようなエクスペリエンスは、現在のエクスペリエンスからのステップ変更であり、ビデオと音声のパラダイムを新しいメディアに適用しています。</span><span class="sxs-lookup"><span data-stu-id="efe07-198">An experience like this is a step-change from our current experience — applying the paradigm of video and voice to a new medium.</span></span> <span data-ttu-id="efe07-199">しかし、将来的に見られるように、混合現実の強度を反映するシナリオとビルドエクスペリエンスの機会をより適切に定義する必要があります。</span><span class="sxs-lookup"><span data-stu-id="efe07-199">But as we look to the future, we must better define the opportunity of our scenarios and build experiences that reflect the strength of mixed reality.</span></span>

<span data-ttu-id="efe07-200">NASA のジェット推進研究所によって開発された、 [Onsight コラボレーションツール](https://www.youtube.com/watch?v=XtUyUJAVQ6w)を考えてみましょう。</span><span class="sxs-lookup"><span data-stu-id="efe07-200">Consider the [OnSight collaboration tool](https://www.youtube.com/watch?v=XtUyUJAVQ6w), developed by NASA’s Jet Propulsion Laboratory.</span></span> <span data-ttu-id="efe07-201">Rover ミッションのデータを操作する科学者は、Martian ランドスケープのデータ内で同僚と共同作業を行うことができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-201">Scientists working on data from the Mars rover missions can collaborate with colleagues in real-time within the data from the Martian landscape.</span></span>

![リモートで分離された同僚と Mars Rover の計画作業を相互に連携させる](images/onsight-nasa-jpl.gif)

<span data-ttu-id="efe07-203">*科学者は、3d デバイスと**2d**デバイスを使用して、**少数**の**リモート**仕事仲間グループを持つ、 **3d の混合現実**デバイスを使用した環境を探索します。**コラボレーション**は**同期**されていますが (非同期に再検討できます)、物理的な環境は (事実上)**似**ています。*</span><span class="sxs-lookup"><span data-stu-id="efe07-203">*A scientist explores an environment using a **3D, mixed-reality** device with a **small** group of **remote** colleagues using **3D and 2D** devices. The **collaboration** is **synchronous** (but can be revisited asynchronously) and the physical environments are (virtually) **similar**.*</span></span>

<span data-ttu-id="efe07-204">OnSight のような経験があれば、コラボレーションが新たにチャンスになります。</span><span class="sxs-lookup"><span data-stu-id="efe07-204">Experiences like OnSight present new opportunities to collaborate.</span></span> <span data-ttu-id="efe07-205">仮想環境内の要素を、同僚の隣に向かって物理的にポイントし、その結果を説明するためにそれらの視点を共有します。</span><span class="sxs-lookup"><span data-stu-id="efe07-205">From physically pointing out elements in the virtual environment to standing next to a colleague and sharing their perspective as they explain their findings.</span></span> <span data-ttu-id="efe07-206">Immersion のレンズとプレゼンスを使用して、mixed reality での共有エクスペリエンスを再考します。</span><span class="sxs-lookup"><span data-stu-id="efe07-206">OnSight uses the lens of immersion and presence to rethink sharing experiences in mixed reality.</span></span>

<span data-ttu-id="efe07-207">直感的なコラボレーションとは、会話の基盤、連携して、この直感を mixed reality の複雑さに適用する方法を理解することが重要です。</span><span class="sxs-lookup"><span data-stu-id="efe07-207">Intuitive collaboration is the bedrock of conversation, working together and understanding how we can apply this intuition to the complexity of mixed reality is crucial.</span></span> <span data-ttu-id="efe07-208">混合環境での共有エクスペリエンスを再作成するだけでなく、それを大量に使用できる場合は、将来の作業のパラダイムシフトになります。</span><span class="sxs-lookup"><span data-stu-id="efe07-208">If we can not only recreate sharing experiences in mixed reality but supercharge them, it will be a paradigm shift for the future of work.</span></span> <span data-ttu-id="efe07-209">混合環境での共有エクスペリエンスの設計は、新たに魅力的なスペースです。最初にしかありません。</span><span class="sxs-lookup"><span data-stu-id="efe07-209">Designing for shared experiences in mixed reality is new and exciting space — and we’re only at the beginning.</span></span>

## <a name="get-started-building-shared-experiences"></a><span data-ttu-id="efe07-210">共有エクスペリエンスの構築を開始する</span><span class="sxs-lookup"><span data-stu-id="efe07-210">Get started building shared experiences</span></span>

<span data-ttu-id="efe07-211">アプリケーションとシナリオに応じて、必要なエクスペリエンスを実現するためのさまざまな要件があります。</span><span class="sxs-lookup"><span data-stu-id="efe07-211">Depending on your application and scenario, there will be various requirements to achieve your desired experience.</span></span> <span data-ttu-id="efe07-212">次のようなものがあります。</span><span class="sxs-lookup"><span data-stu-id="efe07-212">Some of these include:</span></span>

* <span data-ttu-id="efe07-213">**一致**: セッションの作成、セッションのアドバタイズ、特定のユーザーの検出と招待を、ローカルとリモートの両方でセッションに参加させることができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-213">**Match-making**: Ability to create sessions, advertise sessions, discover and invite specific people, both locally and remotely to join your session.</span></span>
* <span data-ttu-id="efe07-214">**アンカー共有**: 共通のローカル空間内の複数のデバイス間で座標を調整できるため、ホログラムはすべてのメンバーに対して同じ場所に表示されます。</span><span class="sxs-lookup"><span data-stu-id="efe07-214">**Anchor sharing**: Ability to align coordinates across multiple devices in a common local space, so holograms appear in the same place for all people.</span></span>
* <span data-ttu-id="efe07-215">**ネットワーク**: すべての参加者に対して、人とホログラムの位置、相互作用、および移動をリアルタイムで同期させる機能。</span><span class="sxs-lookup"><span data-stu-id="efe07-215">**Networking**: Ability to have positions, interactions and movements of people and holograms synchronized in real-time across all participants.</span></span>
* <span data-ttu-id="efe07-216">**状態の格納**: ホログラムの特性と場所を、セッション間の結合のためのスペースに格納する機能、後で再呼び出し、ネットワークの問題に対する堅牢性。</span><span class="sxs-lookup"><span data-stu-id="efe07-216">**State storage**: Ability to store hologram characteristics and locations in space for mid-session join, recall at a later time, and robustness against network issues.</span></span>

<span data-ttu-id="efe07-217">共有エクスペリエンスの鍵となるのは、複数のユーザーが自分のデバイスで世界中の同じホログラムを見ることです。多くの場合、アンカーを共有してデバイス間で座標を調整します。</span><span class="sxs-lookup"><span data-stu-id="efe07-217">The key to shared experiences is having multiple users seeing the same holograms in the world on their own device, frequently done by sharing anchors to align coordinates across devices.</span></span>

<span data-ttu-id="efe07-218">アンカーを共有するには、 [Azure 空間アンカー](https://docs.microsoft.com/azure/spatial-anchors)を使用します。</span><span class="sxs-lookup"><span data-stu-id="efe07-218">To share anchors, use the [Azure Spatial Anchors](https://docs.microsoft.com/azure/spatial-anchors):</span></span>

* <span data-ttu-id="efe07-219">まず、ユーザーがホログラムを配置します。</span><span class="sxs-lookup"><span data-stu-id="efe07-219">First the user places the hologram.</span></span>
* <span data-ttu-id="efe07-220">アプリは[空間アンカー](spatial-anchors.md)を作成し、世界中でそのホログラムを正確にピン留めします。</span><span class="sxs-lookup"><span data-stu-id="efe07-220">App creates a [spatial anchor](spatial-anchors.md), to pin that hologram precisely in the world.</span></span>
* <span data-ttu-id="efe07-221">アンカーは、 [Azure 空間アンカー](https://docs.microsoft.com/azure/spatial-anchors/)を介して HoloLens、iOS、および Android デバイスに対して共有できます。</span><span class="sxs-lookup"><span data-stu-id="efe07-221">The anchors can be shared to HoloLens, iOS and Android devices via [Azure Spatial Anchors](https://docs.microsoft.com/azure/spatial-anchors/).</span></span>

<span data-ttu-id="efe07-222">共有空間アンカーを使用すると、各デバイスのアプリには、コンテンツを配置できる[共通の座標](coordinate-systems.md)系が用意されます。</span><span class="sxs-lookup"><span data-stu-id="efe07-222">With a shared spatial anchor, the app on each device now has a [common coordinate system](coordinate-systems.md) in which they can place content.</span></span> <span data-ttu-id="efe07-223">これで、アプリは、同じ場所にホログラムを配置し、向きを指定できるようになりました。</span><span class="sxs-lookup"><span data-stu-id="efe07-223">Now the app can ensure to position and orient the hologram at the same location.</span></span>

<span data-ttu-id="efe07-224">HoloLens デバイスでは、あるデバイスから別のデバイスにアンカーをオフラインで共有することもできます。</span><span class="sxs-lookup"><span data-stu-id="efe07-224">On HoloLens devices, you can also share anchors offline from one device to another.</span></span>  <span data-ttu-id="efe07-225">次のリンクを使用して、アプリケーションに最適なものを決定します。</span><span class="sxs-lookup"><span data-stu-id="efe07-225">Use the links below to decide what's best for your application.</span></span>

## <a name="evaluating-tech-options"></a><span data-ttu-id="efe07-226">技術オプションの評価</span><span class="sxs-lookup"><span data-stu-id="efe07-226">Evaluating tech options</span></span>

<span data-ttu-id="efe07-227">マルチユーザー混合の現実のエクスペリエンスを構築するのに役立つさまざまなサービスおよびテクノロジオプションが用意されています。</span><span class="sxs-lookup"><span data-stu-id="efe07-227">There are various service and technology options available to help build multi-user mixed reality experiences.</span></span>  <span data-ttu-id="efe07-228">パスを選択するのは難しい場合があるため、シナリオに重点を置いた観点から、いくつかのオプションについて詳しく説明します。</span><span class="sxs-lookup"><span data-stu-id="efe07-228">It can be tricky to choose a path, so taking a scenario-focused perspective, some options are detailed below.</span></span>

## <a name="shared-static-holograms-no-interactions"></a><span data-ttu-id="efe07-229">共有スタティックホログラム (相互作用なし)</span><span class="sxs-lookup"><span data-stu-id="efe07-229">Shared static holograms (no interactions)</span></span>

<span data-ttu-id="efe07-230">アプリで[Azure 空間アンカー](https://docs.microsoft.com/azure/spatial-anchors/)を活用します。</span><span class="sxs-lookup"><span data-stu-id="efe07-230">Leverage [Azure Spatial Anchors](https://docs.microsoft.com/azure/spatial-anchors/) in your app.</span></span>  <span data-ttu-id="efe07-231">デバイス間で空間アンカーを有効にして共有すると、ユーザーが同時にホログラムを表示するアプリケーションを作成できます。</span><span class="sxs-lookup"><span data-stu-id="efe07-231">Enabling and sharing spatial anchors across devices allows you to create an application where users see holograms in the same place at the same time.</span></span>  <span data-ttu-id="efe07-232">ユーザーがホログラムと対話し、ホログラムの移動または状態の更新を確認できるようにするには、デバイス間の追加の同期が必要です。</span><span class="sxs-lookup"><span data-stu-id="efe07-232">Additional syncing across devices is needed to enable users to interact with holograms and see movements or state updates of holograms.</span></span>

## <a name="share-1st-person-perspective"></a><span data-ttu-id="efe07-233">ファーストユーザーの視点を共有する</span><span class="sxs-lookup"><span data-stu-id="efe07-233">Share 1st person perspective</span></span>

<span data-ttu-id="efe07-234">PC や TV など、サポートされている Miracast レシーバーを使用している場合、ローカルユーザーには組み込みの Miracast サポートを利用します。追加のアプリコードは必要ありません。</span><span class="sxs-lookup"><span data-stu-id="efe07-234">Leverage built-in Miracast support, for local users when you have a supported Miracast receiver, such as a PC or TV – no additional app code is needed.</span></span>

<span data-ttu-id="efe07-235">リモートユーザーに対して、または共有したい非 Miracast デバイスがある場合に、アプリで[MixedReality-WebRTC](https://github.com/microsoft/mixedreality-webrtc)を活用します。</span><span class="sxs-lookup"><span data-stu-id="efe07-235">Leverage [MixedReality-WebRTC](https://github.com/microsoft/mixedreality-webrtc) in your app, for remote users or when you have non-Miracast devices that you’d like to share to.</span></span>  <span data-ttu-id="efe07-236">WebRTC 接続を有効にすると、ユーザー間で1:1 のオーディオ/ビデオストリームが有効になり、デバイス間のメッセージング用のデータチャネルも使用できるようになります。</span><span class="sxs-lookup"><span data-stu-id="efe07-236">Enabling a WebRTC connection enables 1:1 audio/video streams between users, with a data channel for messaging across devices, as well.</span></span>  <span data-ttu-id="efe07-237">Mixed reality の実装では、HoloLens ユーザーのビューの混合 reality キャプチャビデオストリームを他のユーザーに提供することで、HoloLens を最適化します。</span><span class="sxs-lookup"><span data-stu-id="efe07-237">The mixed reality implementation optimizes for HoloLens, by providing mixed reality capture video stream of the view of the HoloLens user to others.</span></span>  <span data-ttu-id="efe07-238">複数のリモートクライアントに対してビデオストリーミングをスケールアップする場合は、通常、 [Signalwire](https://signalwire.com/)など、 [MCU サービスプロバイダー](https://webrtcglossary.com/mcu/) (Multipoint 会議単位) が使用されます。</span><span class="sxs-lookup"><span data-stu-id="efe07-238">If you desire to scale up video streaming to multiple remote clients, an [MCU service provider](https://webrtcglossary.com/mcu/) (Multipoint Conferencing Unit) is typically used, such as [SignalWire](https://signalwire.com/).</span></span>  <span data-ttu-id="efe07-239">Azure へのワンクリック SignalWire デプロイは、 [Freeswitch](https://github.com/andywolk/azure-freeswitch-gpu-windows)経由で利用できます。</span><span class="sxs-lookup"><span data-stu-id="efe07-239">A one-click SignalWire deployment to Azure is available via [Freeswitch](https://github.com/andywolk/azure-freeswitch-gpu-windows).</span></span>

> [!NOTE]
> <span data-ttu-id="efe07-240">ただし、SignalWire は有料サービスであり、Microsoft との所有/関連はありません。</span><span class="sxs-lookup"><span data-stu-id="efe07-240">Please note that SignalWire is a paid service and is not owned/affiliated with Microsoft.</span></span>

## <a name="presenter-spectator-applications-and-demos"></a><span data-ttu-id="efe07-241">プレゼンター Spectator アプリケーションとデモ</span><span class="sxs-lookup"><span data-stu-id="efe07-241">Presenter-Spectator applications and Demos</span></span>

<span data-ttu-id="efe07-242">[MixedReality-SpectatorView](https://github.com/microsoft/MixedReality-SpectatorView)を利用して、アプリに[specator ビュー機能](spectator-view.md)をもたらします。</span><span class="sxs-lookup"><span data-stu-id="efe07-242">Leverage [MixedReality-SpectatorView](https://github.com/microsoft/MixedReality-SpectatorView) to bring [specator view functionality](spectator-view.md) into your app.</span></span>  <span data-ttu-id="efe07-243">他のデバイス (HL、Android、iOS、およびビデオカメラ) を有効にすると、同じ場所にあるさまざまな観点から HoloLens がどのように見えるかを確認し、ホログラムと対話するホスト HoloLens ユーザーの相互作用に関する更新を受け取ることができます。</span><span class="sxs-lookup"><span data-stu-id="efe07-243">Enable other devices (HL, Android, iOS, and video cameras) to see what the HoloLens sees from a different perspective in the same location, and receive updates on interactions of the host HoloLens user interacting with the holograms.</span></span>  <span data-ttu-id="efe07-244">同じアプリの spectator コンパニオンを使用して、独自の空間パースペクティブから、アプリケーション内のホログラムによってホストが行う処理のビデオを視聴、撮影、記録します。</span><span class="sxs-lookup"><span data-stu-id="efe07-244">Watch, take pictures, and record video of what the host does with the holograms in the application from your own spatial perspective with the spectator companion of the same app.</span></span>

<span data-ttu-id="efe07-245">**注:** 画像は、iOS/Android デバイスのスクリーンショットを使用して取得されます。</span><span class="sxs-lookup"><span data-stu-id="efe07-245">**Note:** Pictures are taken via screenshot on iOS/Android devices.</span></span>

## <a name="multi-user-collaborative-experience"></a><span data-ttu-id="efe07-246">マルチユーザーコラボレーションエクスペリエンス</span><span class="sxs-lookup"><span data-stu-id="efe07-246">Multi-user collaborative experience</span></span>

<span data-ttu-id="efe07-247">ここでは、[マルチユーザー学習チュートリアル](mrlearning-sharing(photon)-ch1.md)を開始します。このチュートリアルでは、ローカルユーザーと[Photon SDK](https://www.photonengine.com/PUN)の[Azure 空間アンカー](https://docs.microsoft.com/azure/spatial-anchors/)を利用して、シーンのコンテンツ/状態を同期します。</span><span class="sxs-lookup"><span data-stu-id="efe07-247">Start with our [multi-user learning tutorial](mrlearning-sharing(photon)-ch1.md), which leverages [Azure Spatial Anchors](https://docs.microsoft.com/azure/spatial-anchors/) for local users and [Photon SDK](https://www.photonengine.com/PUN) for syncing the content/state in the scene.</span></span> <span data-ttu-id="efe07-248">ローカルに共同作業するアプリケーションを作成します。各ユーザーは、シーン内のホログラムに独自の視点を持ち、各ユーザーがホログラムと完全に対話できます。</span><span class="sxs-lookup"><span data-stu-id="efe07-248">Create locally collaborative applications where each user has his/her own perspective on the holograms in the scene and can each fully interact with the holograms.</span></span>  <span data-ttu-id="efe07-249">すべてのデバイスで更新プログラムが提供され、相互作用の競合管理は Photon によって処理されます。</span><span class="sxs-lookup"><span data-stu-id="efe07-249">Updates are provided across all devices and interaction conflict management is handled by Photon.</span></span>

> [!NOTE]
> <span data-ttu-id="efe07-250">[Photon](https://www.photonengine.com/)はマイクロソフト以外の製品であるため、Photon との課金関係が必要になることがあります。そのため、使用率が高くなるように拡張する必要があります。</span><span class="sxs-lookup"><span data-stu-id="efe07-250">Please note that [Photon](https://www.photonengine.com/) is a non-Microsoft product, so a billing relationship with Photon may be required to productize and scale for higher usage.</span></span>

## <a name="future-work"></a><span data-ttu-id="efe07-251">今後の作業</span><span class="sxs-lookup"><span data-stu-id="efe07-251">Future work</span></span>

<span data-ttu-id="efe07-252">コンポーネントの機能とインターフェイスは、さまざまなシナリオや基盤となるテクノロジに共通の一貫性と堅牢なサポートを提供するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="efe07-252">Component capabilities and interfaces will help in providing common consistency and robust support across the various scenarios and underlying technologies.</span></span>  <span data-ttu-id="efe07-253">それまでは、アプリケーションで達成しようとしているシナリオに合わせた最適なパスを選択します。</span><span class="sxs-lookup"><span data-stu-id="efe07-253">Until then, choose the best path that aligns to the scenario you are trying to achieve in your application.</span></span>

<span data-ttu-id="efe07-254">別のテクノロジ/サービスを使用するシナリオや希望が異なる場合は、</span><span class="sxs-lookup"><span data-stu-id="efe07-254">Different scenario or desire to use a different tech/service?</span></span> <span data-ttu-id="efe07-255">このページの下部にある対応するリポジトリで GitHub の問題としてフィードバックを提供するか、 [HoloDevelopers の余裕期間](https://holodevelopers.slack.com/)にご連絡ください。</span><span class="sxs-lookup"><span data-stu-id="efe07-255">Provide feedback as GitHub issues in the corresponding repo, at the bottom of this page, or reach out on [HoloDevelopers slack](https://holodevelopers.slack.com/).</span></span>

## <a name="see-also"></a><span data-ttu-id="efe07-256">関連項目</span><span class="sxs-lookup"><span data-stu-id="efe07-256">See also</span></span>

* [<span data-ttu-id="efe07-257">Azure Spatial Anchors</span><span class="sxs-lookup"><span data-stu-id="efe07-257">Azure Spatial Anchors</span></span>](https://docs.microsoft.com/azure/spatial-anchors)
* [<span data-ttu-id="efe07-258">DirectX での共有された空間アンカー</span><span class="sxs-lookup"><span data-stu-id="efe07-258">Shared spatial anchors in DirectX</span></span>](shared-spatial-anchors-in-directx.md)
* [<span data-ttu-id="efe07-259">Unity での共有エクスペリエンス</span><span class="sxs-lookup"><span data-stu-id="efe07-259">Shared experiences in Unity</span></span>](shared-experiences-in-unity.md)
* [<span data-ttu-id="efe07-260">Spectator View</span><span class="sxs-lookup"><span data-stu-id="efe07-260">Spectator view</span></span>](spectator-view.md)
