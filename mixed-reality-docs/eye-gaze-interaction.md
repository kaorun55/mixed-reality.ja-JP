---
title: 視線に基づく相互作用
description: HoloLens 2 を使用すると、開発者はユーザーが見ているものについての情報を使用できるので、ホログラフィック エクスペリエンスにおけるコンテキストと人間の理解が大きく進みます。 このページでは、入力として視線を使用する開発者向けの設計に関する推奨事項について説明します。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 視線追跡、Mixed Reality、インプット、視線
ms.openlocfilehash: 93d2cfd82b5aa2a410268c5594b5772bcc0b21c7
ms.sourcegitcommit: a5dc182da237f63f0487d40a2e11894027208b6c
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/02/2019
ms.locfileid: "73441104"
---
# <a name="eye-gaze-based-interaction-on-hololens-2"></a><span data-ttu-id="84ffe-105">HoloLens 2 での視線に基づく対話</span><span class="sxs-lookup"><span data-stu-id="84ffe-105">Eye-gaze-based interaction on HoloLens 2</span></span>

![MRTK の視線追跡デモ](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="84ffe-107">HoloLens 2 のすばらしい新機能の1つは、視線追跡です。</span><span class="sxs-lookup"><span data-stu-id="84ffe-107">One of our exciting new capabilities on HoloLens 2 is eye tracking.</span></span>
<span data-ttu-id="84ffe-108">「 [HoloLens 2 での目の追跡](eye-tracking.md)」ページでは、開発者向けガイダンスや強調表示のために強調表示されているユースケースを使用して、各ユーザーが[調整](https://docs.microsoft.com/hololens/hololens-calibration)を行う必要があることを説明しました。</span><span class="sxs-lookup"><span data-stu-id="84ffe-108">On our [Eye tracking on HoloLens 2](eye-tracking.md) page, we mentioned the need for each user to go through a [Calibration](https://docs.microsoft.com/hololens/hololens-calibration), provided some developer guidance and highlighted use cases for eye tracking.</span></span>
<span data-ttu-id="84ffe-109">目を見つめた入力は、かなり新しい種類のユーザー入力であり、学ぶことはたくさんあります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-109">Eye-gaze input is still a pretty new type of user input and there is a lot to learn.</span></span> <span data-ttu-id="84ffe-110">視線入力は、Holographic シェルエクスペリエンス (HoloLens 2 を開始したときに表示されるユーザーインターフェイス) で非常に微妙に使用されていますが、 ["MR プレイグラウンド"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2)などのいくつかのアプリでは、目を見つめて入力することで、holographic エクスペリエンス。</span><span class="sxs-lookup"><span data-stu-id="84ffe-110">While eye-gaze input is only used very subtly in our Holographic Shell experience (the user interface that you see when you start your HoloLens 2), several apps, such as the ["MR Playground"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2), showcase great examples on how eye-gaze input can add to the magic of your holographic experience.</span></span>
<span data-ttu-id="84ffe-111">このページでは、視線入力を統合して holographic アプリケーションと対話するための設計上の考慮事項について説明します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-111">On this page, we discuss design considerations for integrating eye-gaze input to interact with your holographic applications.</span></span>
<span data-ttu-id="84ffe-112">主な利点について説明するとともに、目を見つめた入力に付随する独自の課題についても説明します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-112">You will learn about key advantages and also unique challenges that come with eye-gaze input.</span></span>  
<span data-ttu-id="84ffe-113">これらの情報に基づいて、サポートされているユーザーインターフェイスの要件を満たすための設計上の推奨事項をいくつか提供します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-113">Based on these, we provide several design recommendations to help you create satisfying eye-gaze-supported user interfaces.</span></span> 

## <a name="device-support"></a><span data-ttu-id="84ffe-114">デバイスのサポート</span><span class="sxs-lookup"><span data-stu-id="84ffe-114">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="84ffe-115"><strong>機能</strong></span><span class="sxs-lookup"><span data-stu-id="84ffe-115"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="84ffe-116"><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 世代)</strong></a></span><span class="sxs-lookup"><span data-stu-id="84ffe-116"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="84ffe-117"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="84ffe-117"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="84ffe-118"><a href="immersive-headset-hardware-details.md"><strong>イマーシブ ヘッドセット</strong></a></span><span class="sxs-lookup"><span data-stu-id="84ffe-118"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="84ffe-119">視線</span><span class="sxs-lookup"><span data-stu-id="84ffe-119">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="84ffe-120">✔️</span><span class="sxs-lookup"><span data-stu-id="84ffe-120">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>


## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="84ffe-121">視線入力のデザインガイドライン</span><span class="sxs-lookup"><span data-stu-id="84ffe-121">Eye-gaze input design guidelines</span></span>
<span data-ttu-id="84ffe-122">高速移動の視点を利用する相互作用を構築するのは困難な場合があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-122">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="84ffe-123">このセクションでは、アプリケーションの設計時に考慮する必要がある主な利点と課題をまとめます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-123">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="84ffe-124">視線入力の利点</span><span class="sxs-lookup"><span data-stu-id="84ffe-124">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="84ffe-125">**高速ポインティング。**</span><span class="sxs-lookup"><span data-stu-id="84ffe-125">**High speed pointing.**</span></span> <span data-ttu-id="84ffe-126">視線筋肉は、人間の本文で最も速く反応する筋肉です。</span><span class="sxs-lookup"><span data-stu-id="84ffe-126">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="84ffe-127">**低労力。**</span><span class="sxs-lookup"><span data-stu-id="84ffe-127">**Low effort.**</span></span> <span data-ttu-id="84ffe-128">身体の動きがほとんど必要ありません。</span><span class="sxs-lookup"><span data-stu-id="84ffe-128">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="84ffe-129">**暗黙。**</span><span class="sxs-lookup"><span data-stu-id="84ffe-129">**Implicitness.**</span></span> <span data-ttu-id="84ffe-130">多くの場合、ユーザーによって "覚えている" ことが示されます。ユーザーの目の動きに関する情報によって、ユーザーがどのターゲットに参加するかをシステムが把握できるようになります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-130">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="84ffe-131">**代替入力チャネル。**</span><span class="sxs-lookup"><span data-stu-id="84ffe-131">**Alternative input channel.**</span></span> <span data-ttu-id="84ffe-132">視線を使用すると、ユーザーからの手動による調整に基づく長年の経験に基づいて、手書き入力や音声入力に対する強力なサポート入力を提供できます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-132">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="84ffe-133">**視覚的注意。**</span><span class="sxs-lookup"><span data-stu-id="84ffe-133">**Visual attention.**</span></span> <span data-ttu-id="84ffe-134">もう1つの重要な利点は、ユーザーがどのようなことに注目しているかを推測できることです。</span><span class="sxs-lookup"><span data-stu-id="84ffe-134">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="84ffe-135">これは、さまざまなアプリケーション領域において、より効率的なユーザーインターフェイスとリモート通信のためのソーシャルキューの強化を効果的に評価できるようにするために役立ちます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-135">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="84ffe-136">簡単に言うと、入力としての視線を使用すると、高速で簡単なコンテキスト入力信号が提供されます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-136">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual input signal.</span></span> <span data-ttu-id="84ffe-137">これは、*音声*入力や*手動*入力などの他の入力と組み合わせてユーザーの意図を確認する場合に特に強力です。</span><span class="sxs-lookup"><span data-stu-id="84ffe-137">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="84ffe-138">入力としての目を見つめた課題</span><span class="sxs-lookup"><span data-stu-id="84ffe-138">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="84ffe-139">多くの場合、には多くの責任があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-139">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="84ffe-140">視線を使用して、スーパーヒーローのようなユーザーエクスペリエンスを実現することができますが、適切に対応できないことを把握しておくことも重要です。</span><span class="sxs-lookup"><span data-stu-id="84ffe-140">While eye-gaze can be used to create satisfying user experiences which make you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="84ffe-141">ここでは、注意すべきいくつかの*課題*と、視線入力を操作するときの対処方法について説明します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-141">The following discusses some *challenges* to consider and how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="84ffe-142">**視線が "常時オン" になってい**ます。目の蓋を開くと、環境内での作業が開始されます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-142">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="84ffe-143">作成したすべての外観に反応して、アクションを誤って発行しています。これは、時間がかかりすぎているために、満足できない結果になる可能性があるためです。</span><span class="sxs-lookup"><span data-stu-id="84ffe-143">Reacting to every look you make and accidentally issuing actions, because you looked at something for too long, would result in an unsatisfying experience.</span></span>
<span data-ttu-id="84ffe-144">そのため、ターゲットの選択をトリガーするために、*音声コマンド*、*ハンドジェスチャ*、*ボタンクリック*、または拡張熟考を使用して視線を組み合わせることをお勧めします (詳細については、「[視線とコミット](gaze-and-commit-eyes.md)」を参照してください)。</span><span class="sxs-lookup"><span data-stu-id="84ffe-144">Therefore, we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target (for more information see [eye-gaze and commit](gaze-and-commit-eyes.md)).</span></span>
<span data-ttu-id="84ffe-145">また、このソリューションでは、involuntarily によって何かをトリガーすることなく、ユーザーが自由に検索できるモードを使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-145">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="84ffe-146">この問題は、ターゲットを見るときにビジュアルと聴覚のフィードバックをデザインするときにも考慮する必要があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-146">This issue should also be considered when designing visual and auditory feedback when looking at a target.</span></span>
<span data-ttu-id="84ffe-147">すぐにポップアウト効果やホバーサウンドを使用して、ユーザーの過負荷にならないようにしてください。</span><span class="sxs-lookup"><span data-stu-id="84ffe-147">Try not to overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="84ffe-148">はらみはキーです。</span><span class="sxs-lookup"><span data-stu-id="84ffe-148">Subtlety is key.</span></span> <span data-ttu-id="84ffe-149">ここでは、設計に関する[推奨事項](eye-gaze-interaction.md#design-recommendations)について説明する際に、以下のベストプラクティスについて説明します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-149">We will discuss some best practices for this further below when talking about [design recommendations](eye-gaze-interaction.md#design-recommendations).</span></span>

- <span data-ttu-id="84ffe-150">**監視と制御**たとえば、壁の写真を正確にためるとします。</span><span class="sxs-lookup"><span data-stu-id="84ffe-150">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="84ffe-151">写真の縁と周囲を見て、揃っているかどうかを確認します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-151">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="84ffe-152">次に、画像を移動するための入力として目を見つめて使用する方法を考えてみましょう。</span><span class="sxs-lookup"><span data-stu-id="84ffe-152">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="84ffe-153">難しいのではないでしょうか。</span><span class="sxs-lookup"><span data-stu-id="84ffe-153">Difficult, isn't it?</span></span> <span data-ttu-id="84ffe-154">これは、入力と制御の両方に必要な場合に、視線の2つの役割について説明します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-154">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="84ffe-155">**クリックする前に移動する:** クイックターゲットを選択する場合は、ユーザーの目を見つめて、手動でクリックする前 (たとえば、エアタップ) に移動できることが調査によって示されています。</span><span class="sxs-lookup"><span data-stu-id="84ffe-155">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an air tap).</span></span> <span data-ttu-id="84ffe-156">そのため、より低速なコントロール入力 (音声、ハンド、コントローラーなど) を使用して、高速の視線信号を同期するには、特別な注意が必要です。</span><span class="sxs-lookup"><span data-stu-id="84ffe-156">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="84ffe-157">**小さいターゲット:** 少し小さすぎて読むことができないテキストを読み込んだときに感じていることがわかりますか。</span><span class="sxs-lookup"><span data-stu-id="84ffe-157">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="84ffe-158">これにより、目を絞り込むことができます。これは、注目を再調整しようとしているため、気がかかることがあります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-158">This straining feeling on your eyes can cause you to feel tired and worn out, because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="84ffe-159">これは、ユーザーが視点を使用してアプリケーションで小さすぎるターゲットを選択する必要がある場合に、ユーザーに対して呼び出す可能性があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-159">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="84ffe-160">設計に際しては、ユーザーにとって楽しく快適なエクスペリエンスを作るため、ターゲットを視角で 2 度以上にする (さらに大きい方が好ましい) ことをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="84ffe-160">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="84ffe-161">**不規則な視点の移動**この目では、固定から固定への迅速な移動を行います。</span><span class="sxs-lookup"><span data-stu-id="84ffe-161">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="84ffe-162">記録された目の動きのスキャン パスを見ると、視線が不規則に動いていることがわかります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-162">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="84ffe-163">視線は、頭の中や*手の動き*と比較して、すばやく、自然*な*ジャンプに移動します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-163">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="84ffe-164">**信頼性の追跡:** 目を通して精度を調整すると、目が新しい条件に合わせて変化する光がわずかに低下する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-164">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eyes adjust to the new conditions.</span></span>
<span data-ttu-id="84ffe-165">これは必ずしもアプリケーションの設計に影響を与えるわけではありませんが、精度は2°の制限内にあるため、ユーザーが再調整する必要がある場合があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-165">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, it may be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="84ffe-166">設計の推奨事項</span><span class="sxs-lookup"><span data-stu-id="84ffe-166">Design recommendations</span></span>
<span data-ttu-id="84ffe-167">次に示すのは、目を見つめた入力の利点と課題に基づいた、設計に関する特定の推奨事項の一覧です。</span><span class="sxs-lookup"><span data-stu-id="84ffe-167">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="84ffe-168">**視線は、ヘッド見つめと同じではありません。**</span><span class="sxs-lookup"><span data-stu-id="84ffe-168">**Eye-gaze is not the same as Head-gaze:**</span></span>
    - <span data-ttu-id="84ffe-169">**次のように、入力タスクに均等な動きが高速であるかどうかを検討します。** ビューのフィールド全体でターゲットをすばやく選択すると、高速で不規則な目の動きが非常に優れていますが、smooth input 軌道 (描画や encircling の注釈など) を必要とするタスクには適用できません。</span><span class="sxs-lookup"><span data-stu-id="84ffe-169">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="84ffe-170">この場合は、手または頭によるポインティングをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="84ffe-170">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="84ffe-171">**ユーザーの目を見つめた (スライダーやカーソルなど) に直接接続することは避けてください。**</span><span class="sxs-lookup"><span data-stu-id="84ffe-171">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="84ffe-172">カーソルの場合は、投影された視線の信号のわずかなオフセットが原因で "fleeing cursor" 効果が生じる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-172">In case of a cursor, this may result in a "fleeing cursor" effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="84ffe-173">スライダーの場合は、スライダーを目で制御する2つの役割と競合し、オブジェクトが正しい位置にあるかどうかを確認することもできます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-173">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="84ffe-174">スライダーの例については、目を見つめてハンドジェスチャと組み合わせて使用する方がよりわかりやすくなっています。</span><span class="sxs-lookup"><span data-stu-id="84ffe-174">For the example of the slider, it makes more sense to use eye-gaze in combination with hand gestures.</span></span> <span data-ttu-id="84ffe-175">これは、ユーザーがさまざまなスライダーをすばやく簡単に切り替えることができることを意味し、手をピンチ、親指とインデックスの指をつかんで移動させることができます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-175">This means that the user could quickly and effortlessly switch among a number of sliders, raising up their hand and pinching their thumb and index finger to grab and move it.</span></span> <span data-ttu-id="84ffe-176">ピンチが離されると、スライダーは移動を停止します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-176">When the pinch is released, the slider stops moving.</span></span> <span data-ttu-id="84ffe-177">簡単に言うと、ユーザーにとっては特に、ユーザーの信号が不正確になる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-177">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="84ffe-178">**視線を他の入力と結合します。** ハンドジェスチャ、音声コマンド、ボタンの押下など、他の入力との視線追跡の統合には、いくつかの利点があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-178">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, provides several advantages:</span></span>
    - <span data-ttu-id="84ffe-179">**無料監視を許可する:** 私たちの主な役割は、環境を観察することであるということです。ユーザーは、(ビジュアル、聴覚などの) フィードバックまたはアクションをトリガーしなくても、ユーザーが検索できるようにすることが重要です。</span><span class="sxs-lookup"><span data-stu-id="84ffe-179">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important that users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="84ffe-180">視線追跡と別の入力コントロールを組み合わせることにより、視線監視と入力制御モードの間でスムーズに遷移できます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-180">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="84ffe-181">**強力なコンテキストプロバイダー:** 音声コマンドを使用したり、手の形でジェスチャを実行したりしているときに、ユーザーがどこで見ているかについての情報を使用することによって、入力を channeling にシームレスに表示できます。</span><span class="sxs-lookup"><span data-stu-id="84ffe-181">**Powerful context provider:** Using information about where and what the user is looking at while saying a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="84ffe-182">たとえば、 _"put_ the it" を迅速かつ自由に選択し、その目的を特定するだけでシーン全体にホログラムを配置するとします。</span><span class="sxs-lookup"><span data-stu-id="84ffe-182">For example: Say _"put that there"_ to quickly and fluently select and position a hologram across the scene by simply looking at a target and its intended destination.</span></span> 

    - <span data-ttu-id="84ffe-183">マルチ**モーダル入力の同期が必要:** 長い音声コマンドやハンドジェスチャなど、より複雑な追加入力を使用して迅速な移動を組み合わせると、追加の入力コマンドが完了して認識される前に、ユーザーが既に見ているようなリスクがあります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-183">**Need for synchronizing multimodal inputs:** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk that the user already continues to look around before the additional input command is finished and recognized.</span></span> <span data-ttu-id="84ffe-184">したがって、独自の入力コントロール (カスタムハンドジェスチャなど) を作成する場合は、この入力の先頭またはおおよその期間を記録して、ユーザーが過去に見た内容と関連付けられるようにしてください。</span><span class="sxs-lookup"><span data-stu-id="84ffe-184">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="84ffe-185">**視線の追跡入力に関する微妙なフィードバック:** システムが意図したとおりに動作していることを示すためにターゲットを検索するときにフィードバックを提供すると便利ですが、微妙に保つ必要があります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-185">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="84ffe-186">これには、徐々にブレンドを行う、視覚的に強調表示する、またはターゲットのサイズを少し増やした場合など、他の微妙なターゲットの動作を実行することがありますユーザーの現在のワークフローを不必要に中断しています。</span><span class="sxs-lookup"><span data-stu-id="84ffe-186">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target size, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="84ffe-187">**不自然な目の動きを入力として適用しないようにします。** アプリケーションのアクションをトリガーするために、ユーザーが特定の目の動き (宝石のジェスチャ) を実行しないようにします。</span><span class="sxs-lookup"><span data-stu-id="84ffe-187">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="84ffe-188">**不正確性のアカウント:** ユーザーにとってわかりやすく、オフセットとジッターという2種類の不正確性を区別します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-188">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="84ffe-189">オフセットに対処する最も簡単な方法は、操作に十分なサイズのターゲットを提供することです。</span><span class="sxs-lookup"><span data-stu-id="84ffe-189">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="84ffe-190">2°を超える視覚的な角度を参照として使用することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="84ffe-190">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="84ffe-191">たとえば、arm を拡張すると、サムネイルの表示角度が約2°になります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-191">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="84ffe-192">これが次のガイダンスにつながります。</span><span class="sxs-lookup"><span data-stu-id="84ffe-192">This leads to the following guidance:</span></span>
    - <span data-ttu-id="84ffe-193">ユーザーが小さいターゲットを選択することを強制しないでください。</span><span class="sxs-lookup"><span data-stu-id="84ffe-193">Do not force users to select tiny targets.</span></span> <span data-ttu-id="84ffe-194">ここでは、ターゲットが十分に大きく、システムが適切に設計されている場合に、ユーザーの対話を簡単で魔法のない方法で記述しています。</span><span class="sxs-lookup"><span data-stu-id="84ffe-194">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="84ffe-195">ターゲットを小さくしすぎると、ユーザーはエクスペリエンスを疲れる、いらだたしいものと表現します。</span><span class="sxs-lookup"><span data-stu-id="84ffe-195">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
<br>

<span data-ttu-id="84ffe-196">このページには、mixed reality での入力としての視点を理解するのに役立つ概要が示されています。</span><span class="sxs-lookup"><span data-stu-id="84ffe-196">This page provided you with a good overview to get you started understanding eye-gaze as an input in mixed reality.</span></span> <span data-ttu-id="84ffe-197">開発を開始するには、 [Unity](https://aka.ms/mrtk-eyes)と、 [DirectX で](gaze-in-directx.md)の視線に関する情報を確認してください。</span><span class="sxs-lookup"><span data-stu-id="84ffe-197">To get started developing, check out our information on [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="84ffe-198">関連項目</span><span class="sxs-lookup"><span data-stu-id="84ffe-198">See also</span></span>
* [<span data-ttu-id="84ffe-199">快適性</span><span class="sxs-lookup"><span data-stu-id="84ffe-199">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="84ffe-200">DirectX での視線</span><span class="sxs-lookup"><span data-stu-id="84ffe-200">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="84ffe-201">Unity での視線 (Mixed Reality Toolkit)</span><span class="sxs-lookup"><span data-stu-id="84ffe-201">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="84ffe-202">HoloLens 2 の目の追跡</span><span class="sxs-lookup"><span data-stu-id="84ffe-202">Eye tracking on HoloLens 2</span></span>](eye-tracking.md)
* [<span data-ttu-id="84ffe-203">宝石とコミットメント</span><span class="sxs-lookup"><span data-stu-id="84ffe-203">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="84ffe-204">視線入力とドウェル</span><span class="sxs-lookup"><span data-stu-id="84ffe-204">Gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="84ffe-205">音声入力</span><span class="sxs-lookup"><span data-stu-id="84ffe-205">Voice input</span></span>](voice-design.md)
