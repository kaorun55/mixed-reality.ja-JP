---
title: ハンズフリー
description: アプリをハンズフリーに最適化する
author: liamartinez
ms.author: liamar
ms.date: 04/20/2019
ms.topic: article
keywords: Mixed Reality、ハンズフリー、宝石、宝石をターゲット、相互作用、設計
ms.openlocfilehash: b2405f5dca19838271363f53ca377c4f90ca1b36
ms.sourcegitcommit: 6bc6757b9b273a63f260f1716c944603dfa51151
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/01/2019
ms.locfileid: "73435077"
---
# <a name="hands-free"></a>ハンズフリー

## <a name="scenarios"></a>シナリオ

「[相互作用モデルの概要](interaction-fundamentals.md)」で説明されているように、ユーザーとその目的を特定したら、作業を遂行するために機能する際に直面する可能性がある環境や状況の課題を自分で確認します。 たとえば、多くのユーザーは、実際の目標を達成するためにユーザーを使用する必要があります。また、ユーザーには、ハンズオンベースのインターフェイスとの対話が困難になります。 

次のようなシナリオがあります。 
* ユーザーの手が混み合っている間に、タスクをガイドする
* ユーザーの手が混み合っている間の資料の参照
* ハンド疲労
* 追跡できない手袋
* 何かを手にする
* 大きな手のジェスチャを実行するためのソーシャル awkwardness
* 狭いスペース


## <a name="hands-free-modalities"></a>ハンズフリーの感覚様相

### <a name="voice-inputvoice-inputmd"></a>[音声入力](voice-input.md)

音声を使用してコマンドを実行し、インターフェイスを制御すると、必要に応じて複数の手順を柔軟にスキップするための便利な方法が提供されます。 音声入力を使用すると、ユーザーはボタンの名前を自由に読み取り、アクティブ化することができます _("参照してください" と言います)_ 。また、タスクを実行できるデジタルエージェントと会話します。


### <a name="gaze-and-dwellgaze-and-dwellmd"></a>[視線入力とドウェル](gaze-and-dwell.md)

実際には、音声を使用するのは理想的ではなく、可能な場合もあります。 出荷時の環境、プライバシー、またはソーシャル規範はすべて制約となります。 ユーザーは、視線 + 熟考モデルを使用することにより、他の入力を必要とせずにアプリを移動することができます。ユーザーは、ターゲットで (ヘッドや目を使用して) 移動を維持して、アクティブ化するために lingers するだけです。 見つめ + 熟考の個々の設計上の考慮事項の詳細については、「[視線 + 熟考](gaze-and-dwell-eyes.md)」と「[熟考](gaze-and-dwell-head.md)」をご覧ください。


## <a name="transitioning-in-and-out-of-hands-free"></a>ハンドフリーに移行する

これらのシナリオでは、コマンドの実行とナビゲーションのために、ホログラムを使用してハンドを解放することは、アプリケーションをエンドツーエンドで操作するための絶対的な要件から、ユーザーが自由に切り替えることができるようになります。ごと. 

アプリケーションの要件が常にハンズフリーで、熟考、カスタム音声コマンド、または単一の音声コマンドを使用しているかどうかにかかわらず、"select" を使用する場合は、必ず適切なものを UI に作成してください。 

対象ユーザーが自由に自由に切り替えられるようにする必要がある場合は、次の原則を考慮することが重要です。

### <a name="assume-the-user-is-already-in-the-mode-that-they-want-to-switch-to"></a>ユーザーが既に切り替え先のモードになっているとします。
たとえば、ユーザーが工場出荷時にビデオ参照を監視していて、ユーザーが自分の HoloLens でビデオ参照を見ていて、レンチを使用して作業を開始した場合、ほとんどの場合、ボタンを押すためにレンチを押す必要はありません。 彼女は、音声コマンドを使用して音声セッションを呼び出し、熟考を開始するために既に表示されている UI で熟考、"select" という単語を言い出すことができるはずです。

ユーザーは次のことを行うことができます。 
* ハンズフリーのまま、ハンドフリーに切り替える
* 手で手に切り替える
* コントローラーを使用してコントローラーに切り替える 

### <a name="create-redundant-ways-to-switch-modes"></a>モードを切り替えるための冗長な方法を作成する
最初の原則はアクセスに関するものですが、2番目の原則は可用性です。 モードを切り替える方法は1つだけではありません。 

次に例を示します。 
* 音声操作を開始するボタン
* ヘッド宝石と熟考を使用してに移行するための音声コマンド

### <a name="add-a-dash-of-drama"></a>ドラマのダッシュを追加する
モードの切り替えは非常に重要です。このような切り替えが行われたときに、ユーザーが何が起こったかをユーザーに知らせるために、これらの遷移が明示的であっても、劇的なスイッチであることが重要です。 


## <a name="usability-checklist"></a>使いやすさのチェックリスト

**エンドツーエンドであらゆることをユーザーが自由に実行できますか。**
* すべての対話型に自由にアクセスできます
* サイズ変更、配置、スワイプ、タップなどのすべてのカスタムジェスチャに代わるものがあることを確認します。
* UI のプレゼンス、配置、および詳細度を常にユーザーが確実に制御できるようにする
    * UI の取得方法
    * ビューの外にある UI のアドレス指定 (視界)
    * 表示する量 (

**相互作用のしくみは、適切な affordances を使用して学習し、補強するのでしょうか。**

ユーザーが理解している...
* ...どのモードであるか。
* ...このモードでできること
* ...現在の状態を確認できます。
* ...どのように移行できますか。
    
**UI はハンドフリーに最適化されていますか。**   

* 例: 熟考 affordances は、一般的な2D パターンに組み込まれていません。
* 例: オブジェクトの強調表示を使用すると、音声を対象にすることが適切です。
* 例: 音声通話は、有効にする必要があるキャプションに適しています。


## <a name="see-also"></a>関連項目
* [HoloLens 2 の目の追跡](eye-tracking.md)
* [宝石とコミットメント](gaze-and-commit.md)
* [視線入力とドウェル](gaze-and-dwell.md)
* [ハンドダイレクト操作](direct-manipulation.md)
* [ハンドジェスチャ](gaze-and-commit.md#composite-gestures)
* [ハンドポイントとコミット](point-and-commit.md)
* [本能的な操作](interaction-fundamentals.md)
* [音声入力](voice-input.md)
